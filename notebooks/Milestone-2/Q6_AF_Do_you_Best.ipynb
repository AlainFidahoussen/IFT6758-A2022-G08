{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the environment variable defined in the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv();\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.environ['NHL_DATA_DIR'], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import src.visualization.visualize as VizManager\n",
    "import src.features.build_features as FeaturesManager\n",
    "import src.features.select_features as FeaturesSelector\n",
    "import src.features.detect_outliers as OutliersManager\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_year = [2015, 2016, 2017, 2018]\n",
    "season_type = \"Regular\"\n",
    "data_df = FeaturesManager.build_features(seasons_year, season_type, with_player_stats=True, with_strength_stats=True)\n",
    "\n",
    "features_to_keep = FeaturesManager.GetFeaturesToKeep()\n",
    "\n",
    "feature_names, target_name = features_to_keep[0:-1], features_to_keep[-1]\n",
    "feature_names = np.array(feature_names)\n",
    "\n",
    "df_features = data_df[feature_names]\n",
    "df_targets = data_df[target_name]\n",
    "\n",
    "X = df_features\n",
    "y = df_targets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "X_train, y_train = OutliersManager.remove_outliers(X_train, y_train)\n",
    "X_valid, y_valid = OutliersManager.remove_outliers(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 10, 11, 12, 13, 18, 19, 20, 21, 22, 23]\n",
      "[4, 8, 14, 15]\n",
      "[0, 16, 17, 7, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Period', 'Period seconds', 'st_X', 'st_Y', 'Shot Type',\n",
       "       'Shot distance', 'Shot angle', 'Is Empty', 'Strength', 'Rebound',\n",
       "       'Speed From Previous Event', 'Change in Shot Angle',\n",
       "       'Shooter Goal Ratio Last Season', 'Goalie Goal Ratio Last Season',\n",
       "       'Shooter Side', 'Shooter Ice Position', 'Num players With',\n",
       "       'Num players Against', 'Elapsed time since Power Play',\n",
       "       'Last event elapsed time', 'Last event st_X', 'Last event st_Y',\n",
       "       'Last event distance', 'Last event angle'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = [\n",
    "    'Period seconds', 'st_X', 'st_Y', 'Shot distance', 'Shot angle', \n",
    "    'Speed From Previous Event', 'Change in Shot Angle', \n",
    "    'Shooter Goal Ratio Last Season', 'Goalie Goal Ratio Last Season',\n",
    "    'Elapsed time since Power Play', 'Last event elapsed time', 'Last event st_X', 'Last event st_Y', \n",
    "    'Last event distance', 'Last event angle']\n",
    "\n",
    "nominal_columns = ['Shot Type', 'Strength', 'Shooter Side', 'Shooter Ice Position']\n",
    "ordinal_columns = ['Period', 'Num players With', 'Num players Against', 'Is Empty', 'Rebound']\n",
    "\n",
    "numerical_columns_idx = [np.where(X_train.columns == c)[0][0] for c in numerical_columns]\n",
    "nominal_columns_idx = [np.where(X_train.columns == c)[0][0] for c in nominal_columns]\n",
    "ordinal_columns_idx = [np.where(X_train.columns == c)[0][0] for c in ordinal_columns]\n",
    "\n",
    "print(numerical_columns_idx)\n",
    "print(nominal_columns_idx)\n",
    "print(ordinal_columns_idx)\n",
    "\n",
    "X_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.95     55434\n",
      "         1.0       0.70      0.11      0.19      5574\n",
      "\n",
      "    accuracy                           0.91     61008\n",
      "   macro avg       0.81      0.55      0.57     61008\n",
      "weighted avg       0.90      0.91      0.88     61008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Fit Random Forest With Random Forest selector\n",
    "# ---------------------------------------------\n",
    "\n",
    "# median\n",
    "fill_nan = ColumnTransformer(transformers = [\n",
    "    ('cat', SimpleImputer(strategy ='most_frequent'), nominal_columns + ordinal_columns),\n",
    "    ('num', SimpleImputer(strategy ='median'), numerical_columns),\n",
    "], remainder ='passthrough')\n",
    "\n",
    "      \n",
    "one_hot = ColumnTransformer(transformers = [\n",
    "    ('enc', OneHotEncoder(sparse = False), list(range(len(nominal_columns)))),\n",
    "], remainder ='passthrough')\n",
    "\n",
    "\n",
    "# scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# features selectpr\n",
    "selector = FeaturesSelector.SelectFromRandomForest()\n",
    "\n",
    "# classifier\n",
    "clf_forest = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "\n",
    "# pipeline    \n",
    "steps = [('fill_nan', fill_nan), ('one_hot', one_hot),  ('scaler', scaler), ('selector', selector), (\"clf_forest\", clf_forest)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Fit\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "\n",
    "# Report\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgboost = xgb.XGBClassifier()\n",
    "\n",
    "eta = np.linspace(0.1, 1, 10)\n",
    "gamma = np.linspace(0, 5, 10)\n",
    "max_depth = range(2, 20, 2)\n",
    "min_child_weight = range(1, 10, 1)\n",
    "\n",
    "param_distributions = {\n",
    "    'clf_xgboost__eta': eta,\n",
    "    'clf_xgboost__gamma': gamma,\n",
    "    'clf_xgboost__max_depth': max_depth,\n",
    "    'clf_xgboost__min_child_weight': min_child_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.67      0.79     55434\n",
      "         1.0       0.19      0.76      0.31      5738\n",
      "\n",
      "    accuracy                           0.68     61172\n",
      "   macro avg       0.58      0.71      0.55     61172\n",
      "weighted avg       0.89      0.68      0.74     61172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier(\n",
    "    learning_rate='adaptive', \n",
    "    batch_size=32, \n",
    "    early_stopping=True,\n",
    "    random_state=RANDOM_SEED)\n",
    "\n",
    "layer_sizes = [(5, 5, 5), (10, 10, 10), (15, 15, 15), (20, 20, 20)]\n",
    "learning_rate_init = [1e-2, 1e-3, 1e-4]\n",
    "solver = ['sgd', 'adam']\n",
    "activation = ['sigmoid', 'relu']\n",
    "\n",
    "param_distributions = {\n",
    "    'clf_mlp__hidden_layer_sizes': layer_sizes,\n",
    "    'clf_mlp__learning_rate_init': learning_rate_init,\n",
    "    'clf_mlp__solver': solver,\n",
    "    'clf_mlp__activation': activation\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NHL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92f48083c8218174491cd4f669c156bacd48c2621c374208378e0b05beed392f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
